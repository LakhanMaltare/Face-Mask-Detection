{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import cv2,os\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath=r\"E:\\dphi\\face_mask_detection\\train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=os.listdir(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['without_mask', 'with_mask']\n"
     ]
    }
   ],
   "source": [
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[i for i in range(len(categories))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict=dict(zip(categories,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'without_mask': 0, 'with_mask': 1}\n"
     ]
    }
   ],
   "source": [
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=100\n",
    "data=[]\n",
    "target=[]\n",
    "for category in categories:\n",
    "    folder_path=os.path.join(datapath,category)\n",
    "    img_path=os.listdir(folder_path)\n",
    "    for img_names in img_path:\n",
    "        imgp=os.path.join(folder_path,img_names)\n",
    "        img=cv2.imread(imgp)        \n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        resized=cv2.resize(gray,(img_size,img_size))\n",
    "#         img=image.img_to_array(resized)\n",
    "#         img1=np.expand_dims(resized,axis=0)\n",
    "        data.append(resized)\n",
    "        target.append(label_dict[category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=np.array(target)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array(data)/255.0\n",
    "data=np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
    "from keras.utils import np_utils\n",
    "target=np_utils.to_categorical(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11264, 100, 100, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),input_shape=data.shape[1:],activation=\"relu\"))     \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64,(3,3),activation=\"relu\"))     \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# model.add(Conv2D(128,(3,3),activation=\"relu\"))     \n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Conv2D(256,(3,3),activation=\"relu\"))     \n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(.5))          \n",
    "model.add(Dense(50,activation=\"relu\"))\n",
    "model.add(Dense(2,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 98, 98, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 47, 47, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 33856)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 33856)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 50)                1692850   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 1,711,768\n",
      "Trainable params: 1,711,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.optimizers import SGD\n",
    "# sgd=SGD(lr=.01,decay=1e-6,momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "271/271 [==============================] - 63s 234ms/step - loss: 0.2883 - accuracy: 0.8843 - val_loss: 0.1918 - val_accuracy: 0.9349\n",
      "Epoch 2/5\n",
      "271/271 [==============================] - 68s 252ms/step - loss: 0.1620 - accuracy: 0.9462 - val_loss: 0.1618 - val_accuracy: 0.9463\n",
      "Epoch 3/5\n",
      "271/271 [==============================] - 66s 243ms/step - loss: 0.1335 - accuracy: 0.9540 - val_loss: 0.1512 - val_accuracy: 0.9532\n",
      "Epoch 4/5\n",
      "271/271 [==============================] - 67s 248ms/step - loss: 0.1075 - accuracy: 0.9628 - val_loss: 0.1383 - val_accuracy: 0.9571\n",
      "Epoch 5/5\n",
      "271/271 [==============================] - 67s 248ms/step - loss: 0.0858 - accuracy: 0.9686 - val_loss: 0.1426 - val_accuracy: 0.9522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1853c4cc708>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,train_target,validation_split=.2,epochs=5,batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to test on several images\n",
    "# testingp=r\"E:\\dphi\\face_mask_detection\\test\"\n",
    "# images=os.listdir(testingp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing import image\n",
    "# prd=[]\n",
    "# for img in images:\n",
    "#     path=os.path.join(testingp,img)\n",
    "#     img=image.load_img(path,target_size=(100,100))\n",
    "#     img=image.img_to_array(img)\n",
    "#     img=np.expand_dims(img,axis=0)\n",
    "#     pr=model.predict(img)\n",
    "#     if pr[0][0]>=1:\n",
    "#         prd.append(\"without_mask\")\n",
    "#     else:\n",
    "#         prd.append(\"with_mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in prd:\n",
    "#     print(f\"\\'{i}\\',\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Live detection using Opencv\n",
    "face_classifier=cv2.CascadeClassifier('C:/Users/Lenovo/AppData/Local/Programs/Python/Python38/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "from tensorflow.keras.preprocessing import image\n",
    "labels_dict={0:'NO MASK',1:'MASK'}\n",
    "color_dict={0:(0,0,255),1:(0,255,0)}\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_classifier.detectMultiScale(gray,1.3,5) \n",
    "    for (x,y,w,h) in faces:\n",
    "    \n",
    "        face_img=gray[y:y+w,x:x+w]\n",
    "        resized=cv2.resize(face_img,(100,100))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,100,100,1))\n",
    "        normalized=np.expand_dims(normalized,axis=0)\n",
    "        result=model.predict(reshaped)\n",
    "\n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.rectangle(frame,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "        cv2.putText(frame, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,0,0),2)\n",
    "    cv2.imshow(\"live\",frame)\n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
